### rfm_clustering.ipynb : RFM 모형 생성, 고객 군집 분석
- R : 고객당 구매 날짜 갭
- F : 고객당 구매 빈도
- M : 고객당 총 구매액

### regression_ensemble.ipynb : 
1. 단순회귀분석 : 거리, 배송 기간
  - 판매자와 구매자 사이 거리 : haversine 공식 사용
  - 선형 회귀 모델 MSE : 75.48350226340852
  - 이상치 제거 이후 MSE : 0.28312813876209875

2. 다중회귀분석 : 독립변수(1. 판매자와 구매자 사이 거리, 2. 리뷰 점수, 3. 물체 부피) 종속변수 (배송 기간 일 기준)
  - 이상치 제거
  - 로그 변환 (평점은 0~5 사이여서 제외)
  - 라쏘 모형 최적 알파 : 0.01 , MSE(교차 검증) : 0.2124313021013516
    - 검증 세트 따로 만들어서 MSE값 일반화 되었는 지 확인 완료/
  - 랜덤포레스트(하이퍼파라미터 기본값) MSE(교차 검증) : 0.2152232496766034
  
  - 랜덤포레스트 그리드 서치 최적 하이퍼파라미터 : {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 300}
  - 랜덤포레스트(최적 하이퍼파라미터) MSE(교차 검증) : 0.20239361100262418


  - 앙상블 모델 : Gradientboosting, RandomForest, Linear 세 가지 조합.
  - 그라디언트부스팅 최적 하이퍼파라미터 : {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}
  - 앙상블 모델 MSE(교차 검증) : 0.1994701431162004

  - 학습 곡선 해석
  - 1. 모델이 작은 훈련 세트에서 상대적으로 낮은 성능을 보임.
    2. 훈련 세트의 크기가 증가함에 따라 훈련 점수는 조금씩 증가함. 추가적인 데이터가 모델을 더 잘 학습하게 되어 훈련 점수가 조금씩 향상되는 것으로 예상.
    3. 작은 훈련 세트에서부터 검증 점수가 상당히 높음 - 작은 데이터셋에서는 일반화하기 어렵기 때문에 과적합(overfitting)이 발생되었다 봄.
    4. 훈련 세트의 크기가 증가함에 따라 검증 점수가 조금씩 감소 - 검증 점수의 변화가 크지 않으며, 훈련 점수와의 차이가 여전히 큼.

    결론 : 이러한 학습곡선을 통해 모델이 과적합되어 있고, 더 많은 데이터를 통해 일반화 능력을 향상시킬 수 있다는 것을 알 수 있음. 또한 훈련 점수와 검증 점수 간의 차이를 줄이는 것이 모델 성능을 향상시키는 데 중요하다는 것을 알려줌.
